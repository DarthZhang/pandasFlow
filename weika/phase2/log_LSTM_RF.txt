nohup: ignoring input
Using TensorFlow backend.
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: Tesla K40m
major: 3 minor: 5 memoryClockRate (GHz) 0.745
pciBusID 0000:06:00.0
Total memory: 11.17GiB
Free memory: 10.98GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40m, pci bus id: 0000:06:00.0)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 3031 get requests, put_count=2595 evicted_count=1000 eviction_rate=0.385356 and unsatisfied allocation rate=0.506763
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 3149 get requests, put_count=3204 evicted_count=1000 eviction_rate=0.31211 and unsatisfied allocation rate=0.307399
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 256 to 281
Ori Fraud shape: (35131, 837) Ori Normal shape: (150649, 837)
True Fraud shape: (35131, 837) True Normal shape: (87590, 837)
Total samples: 122721
size_data=  835
data dimension= 167
Before set Tensor("keras_learning_phase:0", dtype=bool)
After set  1
Train on 98176 samples, validate on 24545 samples
Epoch 1/100
40s - loss: 0.1955 - mean_absolute_error: 0.1242 - acc: 0.9282 - val_loss: 0.1029 - val_mean_absolute_error: 0.0587 - val_acc: 0.9720
Epoch 2/100
38s - loss: 0.0950 - mean_absolute_error: 0.0558 - acc: 0.9738 - val_loss: 0.0904 - val_mean_absolute_error: 0.0534 - val_acc: 0.9742
Epoch 3/100
38s - loss: 0.0872 - mean_absolute_error: 0.0523 - acc: 0.9753 - val_loss: 0.0861 - val_mean_absolute_error: 0.0522 - val_acc: 0.9765
Epoch 4/100
37s - loss: 0.0793 - mean_absolute_error: 0.0488 - acc: 0.9779 - val_loss: 0.0829 - val_mean_absolute_error: 0.0488 - val_acc: 0.9765
Epoch 5/100
36s - loss: 0.0786 - mean_absolute_error: 0.0481 - acc: 0.9781 - val_loss: 0.0787 - val_mean_absolute_error: 0.0489 - val_acc: 0.9777
Epoch 6/100
39s - loss: 0.0761 - mean_absolute_error: 0.0468 - acc: 0.9788 - val_loss: 0.0788 - val_mean_absolute_error: 0.0469 - val_acc: 0.9781
Epoch 7/100
38s - loss: 0.0737 - mean_absolute_error: 0.0460 - acc: 0.9790 - val_loss: 0.0753 - val_mean_absolute_error: 0.0472 - val_acc: 0.9779
Epoch 8/100
38s - loss: 0.0722 - mean_absolute_error: 0.0455 - acc: 0.9794 - val_loss: 0.0774 - val_mean_absolute_error: 0.0475 - val_acc: 0.9785
Epoch 9/100
38s - loss: 0.0705 - mean_absolute_error: 0.0447 - acc: 0.9801 - val_loss: 0.0741 - val_mean_absolute_error: 0.0445 - val_acc: 0.9794
Epoch 10/100
38s - loss: 0.0698 - mean_absolute_error: 0.0441 - acc: 0.9807 - val_loss: 0.0703 - val_mean_absolute_error: 0.0452 - val_acc: 0.9808
Epoch 11/100
38s - loss: 0.0699 - mean_absolute_error: 0.0442 - acc: 0.9808 - val_loss: 0.0707 - val_mean_absolute_error: 0.0446 - val_acc: 0.9801
Epoch 12/100
37s - loss: 0.0678 - mean_absolute_error: 0.0428 - acc: 0.9817 - val_loss: 0.0709 - val_mean_absolute_error: 0.0440 - val_acc: 0.9807
Epoch 13/100
37s - loss: 0.0669 - mean_absolute_error: 0.0425 - acc: 0.9821 - val_loss: 0.0707 - val_mean_absolute_error: 0.0433 - val_acc: 0.9805
Epoch 14/100
38s - loss: 0.0664 - mean_absolute_error: 0.0424 - acc: 0.9816 - val_loss: 0.0706 - val_mean_absolute_error: 0.0446 - val_acc: 0.9801
Epoch 15/100
37s - loss: 0.0659 - mean_absolute_error: 0.0421 - acc: 0.9823 - val_loss: 0.0687 - val_mean_absolute_error: 0.0433 - val_acc: 0.9804
Epoch 16/100
37s - loss: 0.0656 - mean_absolute_error: 0.0421 - acc: 0.9823 - val_loss: 0.0712 - val_mean_absolute_error: 0.0451 - val_acc: 0.9797
Epoch 17/100
39s - loss: 0.0654 - mean_absolute_error: 0.0419 - acc: 0.9821 - val_loss: 0.0710 - val_mean_absolute_error: 0.0423 - val_acc: 0.9811
Epoch 18/100
38s - loss: 0.0640 - mean_absolute_error: 0.0415 - acc: 0.9827 - val_loss: 0.0674 - val_mean_absolute_error: 0.0417 - val_acc: 0.9824
Epoch 19/100
37s - loss: 0.0634 - mean_absolute_error: 0.0406 - acc: 0.9830 - val_loss: 0.0653 - val_mean_absolute_error: 0.0417 - val_acc: 0.9821
Epoch 20/100
37s - loss: 0.0620 - mean_absolute_error: 0.0407 - acc: 0.9833 - val_loss: 0.0670 - val_mean_absolute_error: 0.0414 - val_acc: 0.9825
Epoch 21/100
38s - loss: 0.0626 - mean_absolute_error: 0.0402 - acc: 0.9832 - val_loss: 0.0674 - val_mean_absolute_error: 0.0419 - val_acc: 0.9818
Epoch 22/100
39s - loss: 0.0614 - mean_absolute_error: 0.0398 - acc: 0.9836 - val_loss: 0.0675 - val_mean_absolute_error: 0.0430 - val_acc: 0.9813
Epoch 23/100
38s - loss: 0.0621 - mean_absolute_error: 0.0402 - acc: 0.9840 - val_loss: 0.0665 - val_mean_absolute_error: 0.0417 - val_acc: 0.9818
Epoch 24/100
39s - loss: 0.0613 - mean_absolute_error: 0.0400 - acc: 0.9838 - val_loss: 0.0653 - val_mean_absolute_error: 0.0405 - val_acc: 0.9824
Epoch 25/100
38s - loss: 0.0606 - mean_absolute_error: 0.0394 - acc: 0.9838 - val_loss: 0.0668 - val_mean_absolute_error: 0.0404 - val_acc: 0.9832
Epoch 26/100
38s - loss: 0.0600 - mean_absolute_error: 0.0392 - acc: 0.9843 - val_loss: 0.0671 - val_mean_absolute_error: 0.0414 - val_acc: 0.9818
Epoch 27/100
38s - loss: 0.0602 - mean_absolute_error: 0.0388 - acc: 0.9844 - val_loss: 0.0692 - val_mean_absolute_error: 0.0416 - val_acc: 0.9816
Epoch 28/100
38s - loss: 0.0596 - mean_absolute_error: 0.0391 - acc: 0.9840 - val_loss: 0.0660 - val_mean_absolute_error: 0.0399 - val_acc: 0.9824
Epoch 29/100
39s - loss: 0.0586 - mean_absolute_error: 0.0384 - acc: 0.9844 - val_loss: 0.0651 - val_mean_absolute_error: 0.0390 - val_acc: 0.9837
Epoch 30/100
38s - loss: 0.0582 - mean_absolute_error: 0.0382 - acc: 0.9847 - val_loss: 0.0662 - val_mean_absolute_error: 0.0408 - val_acc: 0.9817
Epoch 31/100
39s - loss: 0.0598 - mean_absolute_error: 0.0389 - acc: 0.9847 - val_loss: 0.0669 - val_mean_absolute_error: 0.0408 - val_acc: 0.9826
Epoch 32/100
39s - loss: 0.0589 - mean_absolute_error: 0.0379 - acc: 0.9852 - val_loss: 0.0647 - val_mean_absolute_error: 0.0414 - val_acc: 0.9832
Epoch 33/100
39s - loss: 0.0580 - mean_absolute_error: 0.0378 - acc: 0.9854 - val_loss: 0.0660 - val_mean_absolute_error: 0.0403 - val_acc: 0.9834
Epoch 34/100
38s - loss: 0.0578 - mean_absolute_error: 0.0377 - acc: 0.9851 - val_loss: 0.0647 - val_mean_absolute_error: 0.0403 - val_acc: 0.9826
Epoch 35/100
39s - loss: 0.0571 - mean_absolute_error: 0.0377 - acc: 0.9855 - val_loss: 0.0630 - val_mean_absolute_error: 0.0393 - val_acc: 0.9842
Epoch 36/100
38s - loss: 0.0561 - mean_absolute_error: 0.0369 - acc: 0.9855 - val_loss: 0.0646 - val_mean_absolute_error: 0.0394 - val_acc: 0.9826
Epoch 37/100
38s - loss: 0.0566 - mean_absolute_error: 0.0370 - acc: 0.9855 - val_loss: 0.0639 - val_mean_absolute_error: 0.0377 - val_acc: 0.9838
Epoch 38/100
40s - loss: 0.0565 - mean_absolute_error: 0.0374 - acc: 0.9855 - val_loss: 0.0624 - val_mean_absolute_error: 0.0396 - val_acc: 0.9822
Epoch 39/100
37s - loss: 0.0557 - mean_absolute_error: 0.0369 - acc: 0.9852 - val_loss: 0.0650 - val_mean_absolute_error: 0.0402 - val_acc: 0.9828
Epoch 40/100
38s - loss: 0.0560 - mean_absolute_error: 0.0369 - acc: 0.9856 - val_loss: 0.0653 - val_mean_absolute_error: 0.0386 - val_acc: 0.9840
Epoch 41/100
38s - loss: 0.0552 - mean_absolute_error: 0.0367 - acc: 0.9857 - val_loss: 0.0620 - val_mean_absolute_error: 0.0367 - val_acc: 0.9849
Epoch 42/100
39s - loss: 0.0556 - mean_absolute_error: 0.0364 - acc: 0.9858 - val_loss: 0.0678 - val_mean_absolute_error: 0.0400 - val_acc: 0.9825
Epoch 43/100
38s - loss: 0.0552 - mean_absolute_error: 0.0368 - acc: 0.9856 - val_loss: 0.0641 - val_mean_absolute_error: 0.0381 - val_acc: 0.9843
Epoch 44/100
38s - loss: 0.0543 - mean_absolute_error: 0.0359 - acc: 0.9862 - val_loss: 0.0644 - val_mean_absolute_error: 0.0380 - val_acc: 0.9830
Epoch 45/100
38s - loss: 0.0544 - mean_absolute_error: 0.0360 - acc: 0.9866 - val_loss: 0.0669 - val_mean_absolute_error: 0.0389 - val_acc: 0.9829
Epoch 46/100
38s - loss: 0.0547 - mean_absolute_error: 0.0359 - acc: 0.9864 - val_loss: 0.0613 - val_mean_absolute_error: 0.0377 - val_acc: 0.9844
Epoch 47/100
39s - loss: 0.0541 - mean_absolute_error: 0.0356 - acc: 0.9868 - val_loss: 0.0627 - val_mean_absolute_error: 0.0379 - val_acc: 0.9845
Epoch 48/100
38s - loss: 0.0532 - mean_absolute_error: 0.0351 - acc: 0.9872 - val_loss: 0.0630 - val_mean_absolute_error: 0.0377 - val_acc: 0.9835
Epoch 49/100
38s - loss: 0.0539 - mean_absolute_error: 0.0357 - acc: 0.9862 - val_loss: 0.0633 - val_mean_absolute_error: 0.0388 - val_acc: 0.9846
Epoch 50/100
36s - loss: 0.0532 - mean_absolute_error: 0.0355 - acc: 0.9866 - val_loss: 0.0638 - val_mean_absolute_error: 0.0391 - val_acc: 0.9833
Epoch 51/100
39s - loss: 0.0540 - mean_absolute_error: 0.0359 - acc: 0.9862 - val_loss: 0.0618 - val_mean_absolute_error: 0.0379 - val_acc: 0.9843
Epoch 52/100
39s - loss: 0.0526 - mean_absolute_error: 0.0353 - acc: 0.9870 - val_loss: 0.0653 - val_mean_absolute_error: 0.0382 - val_acc: 0.9843
Epoch 53/100
37s - loss: 0.0537 - mean_absolute_error: 0.0356 - acc: 0.9870 - val_loss: 0.0620 - val_mean_absolute_error: 0.0378 - val_acc: 0.9835
Epoch 54/100
37s - loss: 0.0524 - mean_absolute_error: 0.0349 - acc: 0.9873 - val_loss: 0.0628 - val_mean_absolute_error: 0.0375 - val_acc: 0.9842
Epoch 55/100
38s - loss: 0.0530 - mean_absolute_error: 0.0351 - acc: 0.9871 - val_loss: 0.0619 - val_mean_absolute_error: 0.0388 - val_acc: 0.9834
Epoch 56/100
38s - loss: 0.0520 - mean_absolute_error: 0.0349 - acc: 0.9870 - val_loss: 0.0614 - val_mean_absolute_error: 0.0383 - val_acc: 0.9836
Epoch 57/100
37s - loss: 0.0516 - mean_absolute_error: 0.0348 - acc: 0.9872 - val_loss: 0.0612 - val_mean_absolute_error: 0.0378 - val_acc: 0.9845
Epoch 58/100
38s - loss: 0.0523 - mean_absolute_error: 0.0349 - acc: 0.9872 - val_loss: 0.0661 - val_mean_absolute_error: 0.0370 - val_acc: 0.9842
Epoch 59/100
38s - loss: 0.0515 - mean_absolute_error: 0.0343 - acc: 0.9876 - val_loss: 0.0654 - val_mean_absolute_error: 0.0383 - val_acc: 0.9831
Epoch 60/100
38s - loss: 0.0516 - mean_absolute_error: 0.0343 - acc: 0.9874 - val_loss: 0.0643 - val_mean_absolute_error: 0.0383 - val_acc: 0.9837
Epoch 61/100
38s - loss: 0.0524 - mean_absolute_error: 0.0350 - acc: 0.9872 - val_loss: 0.0623 - val_mean_absolute_error: 0.0378 - val_acc: 0.9842
Epoch 62/100
38s - loss: 0.0509 - mean_absolute_error: 0.0341 - acc: 0.9879 - val_loss: 0.0603 - val_mean_absolute_error: 0.0370 - val_acc: 0.9851
Epoch 63/100
38s - loss: 0.0515 - mean_absolute_error: 0.0348 - acc: 0.9874 - val_loss: 0.0626 - val_mean_absolute_error: 0.0387 - val_acc: 0.9837
Epoch 64/100
38s - loss: 0.0500 - mean_absolute_error: 0.0339 - acc: 0.9880 - val_loss: 0.0629 - val_mean_absolute_error: 0.0373 - val_acc: 0.9846
Epoch 65/100
39s - loss: 0.0507 - mean_absolute_error: 0.0337 - acc: 0.9880 - val_loss: 0.0617 - val_mean_absolute_error: 0.0365 - val_acc: 0.9856
Epoch 66/100
38s - loss: 0.0507 - mean_absolute_error: 0.0338 - acc: 0.9876 - val_loss: 0.0648 - val_mean_absolute_error: 0.0374 - val_acc: 0.9838
Epoch 67/100
38s - loss: 0.0499 - mean_absolute_error: 0.0335 - acc: 0.9879 - val_loss: 0.0668 - val_mean_absolute_error: 0.0374 - val_acc: 0.9832
Epoch 68/100
38s - loss: 0.0502 - mean_absolute_error: 0.0340 - acc: 0.9873 - val_loss: 0.0639 - val_mean_absolute_error: 0.0378 - val_acc: 0.9837
Epoch 69/100
38s - loss: 0.0498 - mean_absolute_error: 0.0335 - acc: 0.9881 - val_loss: 0.0635 - val_mean_absolute_error: 0.0365 - val_acc: 0.9851
Epoch 70/100
38s - loss: 0.0509 - mean_absolute_error: 0.0337 - acc: 0.9878 - val_loss: 0.0651 - val_mean_absolute_error: 0.0371 - val_acc: 0.9833
Epoch 71/100
38s - loss: 0.0495 - mean_absolute_error: 0.0337 - acc: 0.9878 - val_loss: 0.0622 - val_mean_absolute_error: 0.0371 - val_acc: 0.9838
Epoch 72/100
38s - loss: 0.0491 - mean_absolute_error: 0.0332 - acc: 0.9880 - val_loss: 0.0620 - val_mean_absolute_error: 0.0365 - val_acc: 0.9838
Epoch 73/100
38s - loss: 0.0491 - mean_absolute_error: 0.0334 - acc: 0.9882 - val_loss: 0.0638 - val_mean_absolute_error: 0.0369 - val_acc: 0.9844
Epoch 74/100
37s - loss: 0.0491 - mean_absolute_error: 0.0334 - acc: 0.9884 - val_loss: 0.0649 - val_mean_absolute_error: 0.0383 - val_acc: 0.9831
Epoch 75/100
38s - loss: 0.0508 - mean_absolute_error: 0.0341 - acc: 0.9881 - val_loss: 0.0607 - val_mean_absolute_error: 0.0368 - val_acc: 0.9850
Epoch 76/100
37s - loss: 0.0488 - mean_absolute_error: 0.0331 - acc: 0.9883 - val_loss: 0.0600 - val_mean_absolute_error: 0.0364 - val_acc: 0.9850
Epoch 77/100
38s - loss: 0.0486 - mean_absolute_error: 0.0332 - acc: 0.9884 - val_loss: 0.0629 - val_mean_absolute_error: 0.0361 - val_acc: 0.9846
Epoch 78/100
38s - loss: 0.0485 - mean_absolute_error: 0.0333 - acc: 0.9886 - val_loss: 0.0632 - val_mean_absolute_error: 0.0370 - val_acc: 0.9845
Epoch 79/100
38s - loss: 0.0486 - mean_absolute_error: 0.0333 - acc: 0.9881 - val_loss: 0.0618 - val_mean_absolute_error: 0.0373 - val_acc: 0.9841
Epoch 80/100
38s - loss: 0.0486 - mean_absolute_error: 0.0330 - acc: 0.9886 - val_loss: 0.0633 - val_mean_absolute_error: 0.0370 - val_acc: 0.9839
Epoch 81/100
38s - loss: 0.0490 - mean_absolute_error: 0.0331 - acc: 0.9881 - val_loss: 0.0633 - val_mean_absolute_error: 0.0362 - val_acc: 0.9845
Epoch 82/100
38s - loss: 0.0495 - mean_absolute_error: 0.0337 - acc: 0.9883 - val_loss: 0.0615 - val_mean_absolute_error: 0.0364 - val_acc: 0.9852
Epoch 83/100
38s - loss: 0.0484 - mean_absolute_error: 0.0328 - acc: 0.9885 - val_loss: 0.0629 - val_mean_absolute_error: 0.0360 - val_acc: 0.9850
Epoch 84/100
39s - loss: 0.0482 - mean_absolute_error: 0.0330 - acc: 0.9886 - val_loss: 0.0616 - val_mean_absolute_error: 0.0365 - val_acc: 0.9854
Epoch 85/100
38s - loss: 0.0492 - mean_absolute_error: 0.0334 - acc: 0.9885 - val_loss: 0.0624 - val_mean_absolute_error: 0.0353 - val_acc: 0.9859
Epoch 86/100
39s - loss: 0.0472 - mean_absolute_error: 0.0320 - acc: 0.9896 - val_loss: 0.0622 - val_mean_absolute_error: 0.0345 - val_acc: 0.9853
Epoch 87/100
38s - loss: 0.0485 - mean_absolute_error: 0.0324 - acc: 0.9891 - val_loss: 0.0624 - val_mean_absolute_error: 0.0362 - val_acc: 0.9852
Epoch 88/100
38s - loss: 0.0490 - mean_absolute_error: 0.0328 - acc: 0.9886 - val_loss: 0.0623 - val_mean_absolute_error: 0.0362 - val_acc: 0.9855
Epoch 89/100
37s - loss: 0.0473 - mean_absolute_error: 0.0326 - acc: 0.9888 - val_loss: 0.0626 - val_mean_absolute_error: 0.0360 - val_acc: 0.9859
Epoch 90/100
39s - loss: 0.0477 - mean_absolute_error: 0.0323 - acc: 0.9890 - val_loss: 0.0625 - val_mean_absolute_error: 0.0362 - val_acc: 0.9845
Epoch 91/100
37s - loss: 0.0469 - mean_absolute_error: 0.0323 - acc: 0.9889 - val_loss: 0.0617 - val_mean_absolute_error: 0.0357 - val_acc: 0.9854
Epoch 92/100
38s - loss: 0.0468 - mean_absolute_error: 0.0319 - acc: 0.9894 - val_loss: 0.0653 - val_mean_absolute_error: 0.0364 - val_acc: 0.9839
Epoch 93/100
39s - loss: 0.0466 - mean_absolute_error: 0.0316 - acc: 0.9893 - val_loss: 0.0607 - val_mean_absolute_error: 0.0350 - val_acc: 0.9859
Epoch 94/100
37s - loss: 0.0473 - mean_absolute_error: 0.0320 - acc: 0.9889 - val_loss: 0.0610 - val_mean_absolute_error: 0.0357 - val_acc: 0.9853
Epoch 95/100
38s - loss: 0.0461 - mean_absolute_error: 0.0314 - acc: 0.9897 - val_loss: 0.0654 - val_mean_absolute_error: 0.0372 - val_acc: 0.9834
Epoch 96/100
38s - loss: 0.0467 - mean_absolute_error: 0.0320 - acc: 0.9890 - val_loss: 0.0607 - val_mean_absolute_error: 0.0359 - val_acc: 0.9854
Epoch 97/100
38s - loss: 0.0480 - mean_absolute_error: 0.0325 - acc: 0.9890 - val_loss: 0.0643 - val_mean_absolute_error: 0.0366 - val_acc: 0.9842
Epoch 98/100
38s - loss: 0.0472 - mean_absolute_error: 0.0321 - acc: 0.9894 - val_loss: 0.0632 - val_mean_absolute_error: 0.0366 - val_acc: 0.9842
Epoch 99/100
38s - loss: 0.0468 - mean_absolute_error: 0.0321 - acc: 0.9890 - val_loss: 0.0621 - val_mean_absolute_error: 0.0362 - val_acc: 0.9848
Epoch 100/100
38s - loss: 0.0453 - mean_absolute_error: 0.0313 - acc: 0.9895 - val_loss: 0.0614 - val_mean_absolute_error: 0.0358 - val_acc: 0.9850
After set  0
  128/24545 [..............................] - ETA: 28s  640/24545 [..............................] - ETA: 7s  1152/24545 [>.............................] - ETA: 5s 1664/24545 [=>............................] - ETA: 4s 2176/24545 [=>............................] - ETA: 3s 2688/24545 [==>...........................] - ETA: 3s 3200/24545 [==>...........................] - ETA: 3s 3712/24545 [===>..........................] - ETA: 3s 4224/24545 [====>.........................] - ETA: 2s 4736/24545 [====>.........................] - ETA: 2s 5248/24545 [=====>........................] - ETA: 2s 5760/24545 [======>.......................] - ETA: 2s 6272/24545 [======>.......................] - ETA: 2s 6784/24545 [=======>......................] - ETA: 2s 7296/24545 [=======>......................] - ETA: 2s 7808/24545 [========>.....................] - ETA: 2s 8320/24545 [=========>....................] - ETA: 2s 8832/24545 [=========>....................] - ETA: 2s 9344/24545 [==========>...................] - ETA: 1s 9728/24545 [==========>...................] - ETA: 1s10240/24545 [===========>..................] - ETA: 1s10752/24545 [============>.................] - ETA: 1s11264/24545 [============>.................] - ETA: 1s11776/24545 [=============>................] - ETA: 1s12288/24545 [==============>...............] - ETA: 1s12800/24545 [==============>...............] - ETA: 1s13312/24545 [===============>..............] - ETA: 1s13824/24545 [===============>..............] - ETA: 1s14336/24545 [================>.............] - ETA: 1s14848/24545 [=================>............] - ETA: 1s15360/24545 [=================>............] - ETA: 1s15872/24545 [==================>...........] - ETA: 1s16384/24545 [===================>..........] - ETA: 1s16896/24545 [===================>..........] - ETA: 0s17408/24545 [====================>.........] - ETA: 0s17920/24545 [====================>.........] - ETA: 0s18432/24545 [=====================>........] - ETA: 0s18944/24545 [======================>.......] - ETA: 0s19456/24545 [======================>.......] - ETA: 0s19968/24545 [=======================>......] - ETA: 0s20480/24545 [========================>.....] - ETA: 0s20992/24545 [========================>.....] - ETA: 0s21504/24545 [=========================>....] - ETA: 0s22016/24545 [=========================>....] - ETA: 0s22528/24545 [==========================>...] - ETA: 0s23040/24545 [===========================>..] - ETA: 0s23552/24545 [===========================>..] - ETA: 0s24064/24545 [============================>.] - ETA: 0s24545/24545 [==============================] - 3s     

confusion_matrix:

[[17330   132]
 [  224  6859]]
('Precision:', 0.9811185810327564)
('Recall:', 0.9683749823521107)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
reshape_1 (Reshape)          (None, 5, 167)            0         
_________________________________________________________________
masking_1 (Masking)          (None, 5, 167)            0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 5, 128)            151552    
_________________________________________________________________
dropout_1 (Dropout)          (None, 5, 128)            0         
_________________________________________________________________
lstm_2 (LSTM)                (None, 64)                49408     
_________________________________________________________________
dropout_2 (Dropout)          (None, 64)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 32)                2080      
_________________________________________________________________
dropout_3 (Dropout)          (None, 32)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 33        
=================================================================
Total params: 203,073
Trainable params: 203,073
Non-trainable params: 0
_________________________________________________________________
None
(98176, 32)
(98176, 199)
(98176, 199)
(24545, 199)
start fit RF:

0.98952943573

confusion_matrix:

[[17405   157]
 [  100  6883]]
('Precision:', 0.9776988636363636)
('Recall:', 0.9856795073750537)
